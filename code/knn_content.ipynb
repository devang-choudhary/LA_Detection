{"cells":[{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["from sklearn.metrics import classification_report\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.model_selection import train_test_split\n","from sklearn.multioutput import MultiOutputClassifier\n","import pandas as pd\n","from sklearn.utils import shuffle"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["def get_df(a,project):\n","    # load the model\n","    df = pd.read_csv(f'../data/{project}_final.csv')\n","    # drop all rows in df\n","    df = df.drop(df.index)\n","    print(df.shape)\n","    for p,u in a.items():\n","        if p == project:\n","            continue\n","        df1 = pd.read_csv(f'../data/{p}_final.csv')\n","        df = pd.concat([df,df1])\n","    # \"access_modifier\",\"return_type\",\"method_name\",\"parameters\",\"returns\",\"comments\",content,path\n","    df = df.drop(columns=[\"access_modifier\",\"return_type\",\"method_name\",\"parameters\",\"returns\",\"comments\"],axis=1)\n","    # Count the number of rows in the \"not_smell\" class\n","    # not_smell_count = (df['catagory'] == 'not_smell').sum()\n","\n","    # # Calculate the number of rows to drop (one-third of the count)\n","    # rows_to_drop = not_smell_count // 3\n","\n","    # # Filter the DataFrame to exclude one-third of the \"not_smell\" class\n","    # filtered_smell = df[df['catagory'] == 'not_smeel'].sample(frac=(1/3))  # Selecting 2/3 of 'not_smell' instances\n","    # # print(filtered_smell.shape)\n","    \n","    # defalut_smell = df[df['catagory'] != 'not_smeel']\n","    # print(defalut_smell.shape)\n","    # df = pd.concat([filtered_smell, defalut_smell])\n","    \n","    train_df = shuffle(df)\n","    test_df = pd.read_csv(f'../data/{project}_final.csv')\n","    test_df = test_df.drop(columns=[\"access_modifier\",\"return_type\",\"method_name\",\"parameters\",\"returns\",\"comments\"],axis=1)\n","    # print(df['catagory'].value_counts())\n","    \n","    # df = df.sample(frac=1).reset_index(drop=True)\n","    \n","    # np.random.seed(42)\n","    # p = 0.1 # 10% for test set\n","    # prop = 1-p\n","    # temp_df = df.copy()\n","    # msk = np.random.rand(len(temp_df)) < prop\n","    # train_df = temp_df[msk]\n","    # test_df = temp_df[~msk]\n","    # print(train_df[\"label\"].value_counts())\n","    # print(test_df[\"label\"].value_counts())\n","    # test_df['index'] = test_df.index\n","    # train_df['index'] = train_df.index  \n","    return train_df, test_df"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def get_df_temp(a,project):\n","    df = pd.read_csv(f'../data/{project}_final.csv')\n","    df.drop(columns=[\"access_modifier\",\"return_type\",\"method_name\",\"parameters\",\"returns\",\"comments\"],axis=1,inplace=True)\n","    train_df, test_df = train_test_split(df, train_size=.8, random_state=42)\n","    print(train_df.shape)\n","    print(test_df.shape)\n","    return train_df, test_df"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[],"source":["# Create the KNN model\n","def model_(train_df,test_df):\n","    tfidf_vectorizer = TfidfVectorizer(max_features=50)\n","    X_train = tfidf_vectorizer.fit_transform(train_df['content'])\n","    X_test = tfidf_vectorizer.transform(test_df['content'])\n","    train_df.drop(columns=['content'], inplace=True)\n","    test_df.drop(columns=['content'], inplace=True)\n","    y_train = train_df.values\n","    y_test = test_df.values\n","    # Create the MultiOutputClassifier\n","    knn = KNeighborsClassifier(n_neighbors=3)\n","    multi_target_knn = MultiOutputClassifier(knn, n_jobs=-1)\n","\n","    # Train the model\n","    multi_target_knn.fit(X_train, y_train)\n","\n","    # Make predictions\n","    predictions = multi_target_knn.predict(X_test)\n","\n","    print(classification_report(y_test, predictions, target_names=['get','DOS','is','set']))\n"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["a = {\n","    \"buildship\": \"https://github.com/eclipse/steady.git\",\n","    \"eclips-collections\": \"https://github.com/eclipse/eclipse-collections.git\",\n","    \"hawkbit\": \"https://github.com/eclipse/hawkbit.git\",\n","    \"jkube\": \"https://github.com/eclipse/jkube.git\",\n","    \"kura\": \"https://github.com/eclipse/kura.git\",\n","    \"jifa\": \"https://github.com/eclipse/microprofile.git\",\n","    \"milo\": \"https://github.com/eclipse/milo.git\",\n","    \"openvsx\": \"https://github.com/eclipse/openvsx.git\",\n","    \"steady\": \"https://github.com/eclipse/steady.git\",\n","    \"xtext\": \"https://github.com/eclipse/xtext.git\"\n","}"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["(0, 11)\n"]},{"name":"stderr","output_type":"stream","text":["/Users/devang/miniconda3/envs/flask/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/Users/devang/miniconda3/envs/flask/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","         get       0.00      0.00      0.00       115\n","         DOS       0.72      0.10      0.17       767\n","          is       0.49      0.32      0.38      1282\n","         set       0.76      0.63      0.69       559\n","\n","   micro avg       0.56      0.31      0.40      2723\n","   macro avg       0.49      0.26      0.31      2723\n","weighted avg       0.59      0.31      0.37      2723\n"," samples avg       0.16      0.15      0.15      2723\n","\n","(0, 11)\n"]},{"name":"stderr","output_type":"stream","text":["/Users/devang/miniconda3/envs/flask/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/Users/devang/miniconda3/envs/flask/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","         get       0.32      0.02      0.03       857\n","         DOS       0.03      0.58      0.05       143\n","          is       0.42      0.22      0.29      1070\n","         set       0.50      0.06      0.10      2362\n","\n","   micro avg       0.11      0.11      0.11      4432\n","   macro avg       0.32      0.22      0.12      4432\n","weighted avg       0.43      0.11      0.13      4432\n"," samples avg       0.06      0.06      0.06      4432\n","\n","(0, 11)\n"]},{"name":"stderr","output_type":"stream","text":["/Users/devang/miniconda3/envs/flask/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/Users/devang/miniconda3/envs/flask/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","         get       0.40      0.35      0.37       272\n","         DOS       0.79      0.56      0.66       249\n","          is       0.39      0.28      0.32       753\n","         set       0.46      0.36      0.40       756\n","\n","   micro avg       0.46      0.35      0.40      2030\n","   macro avg       0.51      0.39      0.44      2030\n","weighted avg       0.47      0.35      0.40      2030\n"," samples avg       0.22      0.22      0.22      2030\n","\n","(0, 11)\n"]},{"name":"stderr","output_type":"stream","text":["/Users/devang/miniconda3/envs/flask/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/Users/devang/miniconda3/envs/flask/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","         get       0.40      0.30      0.34       154\n","         DOS       0.59      0.40      0.47       106\n","          is       0.44      0.20      0.28      1032\n","         set       0.41      0.27      0.33       850\n","\n","   micro avg       0.43      0.25      0.31      2142\n","   macro avg       0.46      0.29      0.36      2142\n","weighted avg       0.43      0.25      0.31      2142\n"," samples avg       0.16      0.15      0.16      2142\n","\n","(0, 11)\n"]},{"name":"stderr","output_type":"stream","text":["/Users/devang/miniconda3/envs/flask/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/Users/devang/miniconda3/envs/flask/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","         get       0.67      0.62      0.65      2679\n","         DOS       0.68      0.46      0.55      2285\n","          is       0.40      0.31      0.35      4182\n","         set       0.32      0.34      0.33      2289\n","\n","   micro avg       0.49      0.42      0.45     11435\n","   macro avg       0.52      0.43      0.47     11435\n","weighted avg       0.50      0.42      0.45     11435\n"," samples avg       0.23      0.23      0.23     11435\n","\n","(0, 11)\n"]},{"name":"stderr","output_type":"stream","text":["/Users/devang/miniconda3/envs/flask/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/Users/devang/miniconda3/envs/flask/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","         get       0.43      0.36      0.39        28\n","         DOS       0.85      0.77      0.80        43\n","          is       0.30      0.17      0.22       209\n","         set       0.45      0.30      0.36       178\n","\n","   micro avg       0.44      0.29      0.35       458\n","   macro avg       0.51      0.40      0.44       458\n","weighted avg       0.42      0.29      0.34       458\n"," samples avg       0.17      0.16      0.16       458\n","\n","(0, 11)\n"]},{"name":"stderr","output_type":"stream","text":["/Users/devang/miniconda3/envs/flask/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/Users/devang/miniconda3/envs/flask/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","         get       0.21      0.69      0.32       312\n","         DOS       0.88      0.05      0.09      1064\n","          is       0.39      0.45      0.42      3292\n","         set       0.17      0.32      0.22       911\n","\n","   micro avg       0.31      0.37      0.34      5579\n","   macro avg       0.41      0.38      0.26      5579\n","weighted avg       0.44      0.37      0.32      5579\n"," samples avg       0.17      0.19      0.18      5579\n","\n","(0, 11)\n"]},{"name":"stderr","output_type":"stream","text":["/Users/devang/miniconda3/envs/flask/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/Users/devang/miniconda3/envs/flask/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","         get       0.69      0.79      0.74       345\n","         DOS       0.82      0.33      0.47       293\n","          is       0.38      0.61      0.47       513\n","         set       0.43      0.17      0.24       404\n","\n","   micro avg       0.50      0.48      0.49      1555\n","   macro avg       0.58      0.48      0.48      1555\n","weighted avg       0.54      0.48      0.47      1555\n"," samples avg       0.25      0.24      0.24      1555\n","\n","(0, 11)\n"]},{"name":"stderr","output_type":"stream","text":["/Users/devang/miniconda3/envs/flask/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/Users/devang/miniconda3/envs/flask/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","         get       0.82      0.38      0.52       494\n","         DOS       0.92      0.79      0.85       767\n","          is       0.44      0.70      0.54      1282\n","         set       0.67      0.62      0.65       559\n","\n","   micro avg       0.59      0.66      0.62      3102\n","   macro avg       0.71      0.62      0.64      3102\n","weighted avg       0.66      0.66      0.63      3102\n"," samples avg       0.35      0.35      0.35      3102\n","\n","(0, 11)\n"]},{"name":"stderr","output_type":"stream","text":["/Users/devang/miniconda3/envs/flask/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/Users/devang/miniconda3/envs/flask/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","         get       0.82      0.52      0.64     16416\n","         DOS       0.26      0.20      0.23      4084\n","          is       0.36      0.36      0.36     17948\n","         set       0.29      0.34      0.31     12075\n","\n","   micro avg       0.44      0.39      0.41     50523\n","   macro avg       0.43      0.36      0.38     50523\n","weighted avg       0.49      0.39      0.43     50523\n"," samples avg       0.22      0.21      0.21     50523\n","\n"]}],"source":["for project, url in a.items():\n","    train_df, test_df = get_df_temp(a,project)\n","    model_(train_df,test_df)"]}],"metadata":{"kernelspec":{"display_name":"flask","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.4"}},"nbformat":4,"nbformat_minor":2}
